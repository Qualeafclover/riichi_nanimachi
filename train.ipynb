{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49eea09d-c545-4f54-8935-d58c37338728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "DATASET_PATH = \"dataset/riichi_ds_v01.npz\"\n",
    "\n",
    "loads = np.load(DATASET_PATH)\n",
    "x, y = torch.tensor(loads[\"x\"].astype(np.float32)), torch.tensor(loads[\"y\"].astype(np.float32))\n",
    "\n",
    "x_test, x_train = x[:20000], x[20000:]\n",
    "y_test, y_train = y[:20000], y[20000:]\n",
    "\n",
    "test_ds = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "train_ds = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=64, shuffle=True)\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cde52e-349e-4488-a847-c8e2a01e35aa",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb39241a-6906-4f6e-85e0-9e51b28e9dc7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Model V1\n",
    "Basic model with structure suggested by <br>\n",
    "https://arxiv.org/pdf/2202.12847"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d734aea-8e5d-4ac9-a291-65ee6e1f050b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 21, 30]           1,344\n",
      "              ReLU-2           [-1, 64, 21, 30]               0\n",
      "       BatchNorm2d-3           [-1, 64, 21, 30]             128\n",
      "           Dropout-4           [-1, 64, 21, 30]               0\n",
      "            Conv2d-5           [-1, 64, 18, 26]          81,984\n",
      "              ReLU-6           [-1, 64, 18, 26]               0\n",
      "       BatchNorm2d-7           [-1, 64, 18, 26]             128\n",
      "           Dropout-8           [-1, 64, 18, 26]               0\n",
      "            Conv2d-9           [-1, 64, 15, 22]          81,984\n",
      "             ReLU-10           [-1, 64, 15, 22]               0\n",
      "      BatchNorm2d-11           [-1, 64, 15, 22]             128\n",
      "          Dropout-12           [-1, 64, 15, 22]               0\n",
      "           Conv2d-13           [-1, 32, 12, 18]          40,992\n",
      "             ReLU-14           [-1, 32, 12, 18]               0\n",
      "      BatchNorm2d-15           [-1, 32, 12, 18]              64\n",
      "          Dropout-16           [-1, 32, 12, 18]               0\n",
      "           Linear-17                  [-1, 256]       1,769,728\n",
      "             ReLU-18                  [-1, 256]               0\n",
      "      BatchNorm1d-19                  [-1, 256]             512\n",
      "          Dropout-20                  [-1, 256]               0\n",
      "           Linear-21                   [-1, 34]           8,738\n",
      "          Sigmoid-22                   [-1, 34]               0\n",
      "================================================================\n",
      "Total params: 1,985,730\n",
      "Trainable params: 1,985,730\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 3.01\n",
      "Params size (MB): 7.57\n",
      "Estimated Total Size (MB): 10.59\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# https://arxiv.org/pdf/2202.12847\n",
    "# ~ No padding or pooling to be used, loses accuracy\n",
    "\n",
    "class ModelV1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelV1, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.conv2d_1 = torch.nn.Conv2d(1, 64, (4, 5))\n",
    "        self.bn_1 = torch.nn.BatchNorm2d(64)\n",
    "        self.conv2d_2 = torch.nn.Conv2d(64, 64, (4, 5))\n",
    "        self.bn_2 = torch.nn.BatchNorm2d(64)\n",
    "        self.conv2d_3 = torch.nn.Conv2d(64, 64, (4, 5))\n",
    "        self.bn_3 = torch.nn.BatchNorm2d(64)\n",
    "        self.conv2d_4 = torch.nn.Conv2d(64, 32, (4, 5))\n",
    "        self.bn_4 = torch.nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.fc_1 = torch.nn.Linear(6912, 256)\n",
    "        self.bn_5 = torch.nn.BatchNorm1d(256)\n",
    "        self.fc_2 = torch.nn.Linear(256, 34)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.unsqueeze(x, -3)\n",
    "        x = self.dropout(self.bn_1(self.relu(self.conv2d_1(x))))\n",
    "        x = self.dropout(self.bn_2(self.relu(self.conv2d_2(x))))\n",
    "        x = self.dropout(self.bn_3(self.relu(self.conv2d_3(x))))\n",
    "        x = self.dropout(self.bn_4(self.relu(self.conv2d_4(x))))\n",
    "        x = torch.flatten(x, 1, -1)\n",
    "        x = self.dropout(self.bn_5(self.relu(self.fc_1(x))))\n",
    "        x = self.sigmoid(self.fc_2(x))\n",
    "        return x\n",
    "\n",
    "summary(ModelV1(), (24, 34), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a6ca13-b4aa-470e-8185-dc4432cdff0f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Model V2\n",
    "Model stacking the type of tiles to form a 4 layer input<br>\n",
    "of manzu, pinzu, soozu, jihai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1e1e2ef9-f306-45d5-9bf0-7ac2d9920246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 64, 19, 9]          10,816\n",
      "              ReLU-2            [-1, 64, 19, 9]               0\n",
      "       BatchNorm2d-3            [-1, 64, 19, 9]             128\n",
      "           Dropout-4            [-1, 64, 19, 9]               0\n",
      "            Conv2d-5            [-1, 64, 14, 9]         172,096\n",
      "              ReLU-6            [-1, 64, 14, 9]               0\n",
      "       BatchNorm2d-7            [-1, 64, 14, 9]             128\n",
      "           Dropout-8            [-1, 64, 14, 9]               0\n",
      "            Conv2d-9             [-1, 64, 9, 9]         172,096\n",
      "             ReLU-10             [-1, 64, 9, 9]               0\n",
      "      BatchNorm2d-11             [-1, 64, 9, 9]             128\n",
      "          Dropout-12             [-1, 64, 9, 9]               0\n",
      "           Conv2d-13             [-1, 32, 4, 9]          86,048\n",
      "             ReLU-14             [-1, 32, 4, 9]               0\n",
      "      BatchNorm2d-15             [-1, 32, 4, 9]              64\n",
      "          Dropout-16             [-1, 32, 4, 9]               0\n",
      "           Conv2d-17              [-1, 4, 1, 9]           3,588\n",
      "          Sigmoid-18              [-1, 4, 1, 9]               0\n",
      "================================================================\n",
      "Total params: 445,092\n",
      "Trainable params: 445,092\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.77\n",
      "Params size (MB): 1.70\n",
      "Estimated Total Size (MB): 2.47\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class ModelV2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelV2, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.bn_1 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn_2 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn_3 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn_4 = torch.nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2d_1 = torch.nn.Conv2d(4, 64, (6, 7), padding=(0, 3))\n",
    "        self.conv2d_2 = torch.nn.Conv2d(64, 64, (6, 7), padding=(0, 3))\n",
    "        self.conv2d_3 = torch.nn.Conv2d(64, 64, (6, 7), padding=(0, 3))\n",
    "        self.conv2d_4 = torch.nn.Conv2d(64, 32, (6, 7), padding=(0, 3))\n",
    "        self.conv2d_5 = torch.nn.Conv2d(32, 4, (4, 7), padding=(0, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_manzu = x[..., 0:9]\n",
    "        x_pinzu = x[..., 9:18]\n",
    "        x_soozu = x[..., 18:27]\n",
    "        x_jihai = torch.nn.functional.pad(x[..., 27:34], (1, 1, 0, 0))\n",
    "        x = torch.stack([x_manzu, x_pinzu, x_soozu, x_jihai], dim=-3)\n",
    "        x = self.dropout(self.bn_1(self.relu(self.conv2d_1(x))))\n",
    "        x = self.dropout(self.bn_2(self.relu(self.conv2d_2(x))))\n",
    "        x = self.dropout(self.bn_3(self.relu(self.conv2d_3(x))))\n",
    "        x = self.dropout(self.bn_4(self.relu(self.conv2d_4(x))))\n",
    "        x = self.sigmoid(self.conv2d_5(x))\n",
    "        x = torch.squeeze(x, dim=-2)\n",
    "        x = torch.concat([x[..., 0, :], x[..., 1, :], x[..., 2, :], x[..., 3, 1:8]], dim=-1)\n",
    "        return x\n",
    "\n",
    "summary(ModelV2(), (24, 34), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17f9634b-4523-4e59-8f48-e6f25b8298f0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 64, 19, 9]           4,672\n",
      "              ReLU-2            [-1, 64, 19, 9]               0\n",
      "       BatchNorm2d-3            [-1, 64, 19, 9]             128\n",
      "           Dropout-4            [-1, 64, 19, 9]               0\n",
      "            Conv2d-5            [-1, 64, 14, 9]          73,792\n",
      "              ReLU-6            [-1, 64, 14, 9]               0\n",
      "       BatchNorm2d-7            [-1, 64, 14, 9]             128\n",
      "           Dropout-8            [-1, 64, 14, 9]               0\n",
      "            Conv2d-9             [-1, 64, 9, 9]          73,792\n",
      "             ReLU-10             [-1, 64, 9, 9]               0\n",
      "      BatchNorm2d-11             [-1, 64, 9, 9]             128\n",
      "          Dropout-12             [-1, 64, 9, 9]               0\n",
      "           Conv2d-13             [-1, 32, 4, 9]          36,896\n",
      "             ReLU-14             [-1, 32, 4, 9]               0\n",
      "      BatchNorm2d-15             [-1, 32, 4, 9]              64\n",
      "          Dropout-16             [-1, 32, 4, 9]               0\n",
      "           Conv2d-17              [-1, 4, 1, 9]           1,540\n",
      "          Sigmoid-18              [-1, 4, 1, 9]               0\n",
      "================================================================\n",
      "Total params: 191,140\n",
      "Trainable params: 191,140\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.77\n",
      "Params size (MB): 0.73\n",
      "Estimated Total Size (MB): 1.51\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Testing the importance of big kernels\n",
    "# Comparing the 6x7 kernels with V2_1's 6x3\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class ModelV2_1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelV2_1, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.bn_1 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn_2 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn_3 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn_4 = torch.nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2d_1 = torch.nn.Conv2d(4, 64, (6, 3), padding=(0, 1))\n",
    "        self.conv2d_2 = torch.nn.Conv2d(64, 64, (6, 3), padding=(0, 1))\n",
    "        self.conv2d_3 = torch.nn.Conv2d(64, 64, (6, 3), padding=(0, 1))\n",
    "        self.conv2d_4 = torch.nn.Conv2d(64, 32, (6, 3), padding=(0, 1))\n",
    "        self.conv2d_5 = torch.nn.Conv2d(32, 4, (4, 3), padding=(0, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_manzu = x[..., 0:9]\n",
    "        x_pinzu = x[..., 9:18]\n",
    "        x_soozu = x[..., 18:27]\n",
    "        x_jihai = torch.nn.functional.pad(x[..., 27:34], (1, 1, 0, 0))\n",
    "        x = torch.stack([x_manzu, x_pinzu, x_soozu, x_jihai], dim=-3)\n",
    "        x = self.dropout(self.bn_1(self.relu(self.conv2d_1(x))))\n",
    "        x = self.dropout(self.bn_2(self.relu(self.conv2d_2(x))))\n",
    "        x = self.dropout(self.bn_3(self.relu(self.conv2d_3(x))))\n",
    "        x = self.dropout(self.bn_4(self.relu(self.conv2d_4(x))))\n",
    "        x = self.sigmoid(self.conv2d_5(x))\n",
    "        x = torch.squeeze(x, dim=-2)\n",
    "        x = torch.concat([x[..., 0, :], x[..., 1, :], x[..., 2, :], x[..., 3, 1:8]], dim=-1)\n",
    "        return x\n",
    "\n",
    "summary(ModelV2_1(), (24, 34), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caa11fb-eb6e-47fc-b469-d66774e7bdb9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Model V3\n",
    "A modification of model V2, but using maxpooling as a method of downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d68e563e-b070-46d2-b726-1e0454199795",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 64, 24, 9]          12,608\n",
      "              ReLU-2            [-1, 64, 24, 9]               0\n",
      "       BatchNorm2d-3            [-1, 64, 24, 9]             128\n",
      "           Dropout-4            [-1, 64, 24, 9]               0\n",
      "         MaxPool2d-5            [-1, 64, 19, 9]               0\n",
      "            Conv2d-6            [-1, 64, 19, 9]         200,768\n",
      "              ReLU-7            [-1, 64, 19, 9]               0\n",
      "       BatchNorm2d-8            [-1, 64, 19, 9]             128\n",
      "           Dropout-9            [-1, 64, 19, 9]               0\n",
      "        MaxPool2d-10            [-1, 64, 14, 9]               0\n",
      "           Conv2d-11            [-1, 64, 14, 9]         200,768\n",
      "             ReLU-12            [-1, 64, 14, 9]               0\n",
      "      BatchNorm2d-13            [-1, 64, 14, 9]             128\n",
      "          Dropout-14            [-1, 64, 14, 9]               0\n",
      "        MaxPool2d-15             [-1, 64, 9, 9]               0\n",
      "           Conv2d-16             [-1, 32, 9, 9]         100,384\n",
      "             ReLU-17             [-1, 32, 9, 9]               0\n",
      "      BatchNorm2d-18             [-1, 32, 9, 9]              64\n",
      "          Dropout-19             [-1, 32, 9, 9]               0\n",
      "        MaxPool2d-20             [-1, 32, 4, 9]               0\n",
      "           Conv2d-21              [-1, 4, 1, 9]           3,588\n",
      "          Sigmoid-22              [-1, 4, 1, 9]               0\n",
      "================================================================\n",
      "Total params: 518,564\n",
      "Trainable params: 518,564\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.27\n",
      "Params size (MB): 1.98\n",
      "Estimated Total Size (MB): 3.26\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class ModelV3(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelV3, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.pool = torch.nn.MaxPool2d((6, 1), stride=1)\n",
    "        \n",
    "        self.bn_1 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn_2 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn_3 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn_4 = torch.nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2d_1 = torch.nn.Conv2d(4, 64, (7, 7), padding=(3, 3))\n",
    "        self.conv2d_2 = torch.nn.Conv2d(64, 64, (7, 7), padding=(3, 3))\n",
    "        self.conv2d_3 = torch.nn.Conv2d(64, 64, (7, 7), padding=(3, 3))\n",
    "        self.conv2d_4 = torch.nn.Conv2d(64, 32, (7, 7), padding=(3, 3))\n",
    "        self.conv2d_5 = torch.nn.Conv2d(32, 4, (4, 7), padding=(0, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_manzu = x[..., 0:9]\n",
    "        x_pinzu = x[..., 9:18]\n",
    "        x_soozu = x[..., 18:27]\n",
    "        x_jihai = torch.nn.functional.pad(x[..., 27:34], (1, 1, 0, 0))\n",
    "        x = torch.stack([x_manzu, x_pinzu, x_soozu, x_jihai], dim=-3)\n",
    "        x = self.pool(self.dropout(self.bn_1(self.relu(self.conv2d_1(x)))))\n",
    "        x = self.pool(self.dropout(self.bn_2(self.relu(self.conv2d_2(x)))))\n",
    "        x = self.pool(self.dropout(self.bn_3(self.relu(self.conv2d_3(x)))))\n",
    "        x = self.pool(self.dropout(self.bn_4(self.relu(self.conv2d_4(x)))))\n",
    "        x = self.sigmoid(self.conv2d_5(x))\n",
    "        x = torch.squeeze(x, dim=-2)\n",
    "        x = torch.concat([x[..., 0, :], x[..., 1, :], x[..., 2, :], x[..., 3, 1:8]], dim=-1)\n",
    "        return x\n",
    "\n",
    "summary(ModelV3(), (24, 34), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d6473fa-c029-4ef5-857d-2b72247882f4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 64, 24, 9]          12,608\n",
      "              ReLU-2            [-1, 64, 24, 9]               0\n",
      "       BatchNorm2d-3            [-1, 64, 24, 9]             128\n",
      "         MaxPool2d-4            [-1, 64, 19, 9]               0\n",
      "           Dropout-5            [-1, 64, 19, 9]               0\n",
      "            Conv2d-6            [-1, 64, 19, 9]         200,768\n",
      "              ReLU-7            [-1, 64, 19, 9]               0\n",
      "       BatchNorm2d-8            [-1, 64, 19, 9]             128\n",
      "         MaxPool2d-9            [-1, 64, 14, 9]               0\n",
      "          Dropout-10            [-1, 64, 14, 9]               0\n",
      "           Conv2d-11            [-1, 64, 14, 9]         200,768\n",
      "             ReLU-12            [-1, 64, 14, 9]               0\n",
      "      BatchNorm2d-13            [-1, 64, 14, 9]             128\n",
      "        MaxPool2d-14             [-1, 64, 9, 9]               0\n",
      "          Dropout-15             [-1, 64, 9, 9]               0\n",
      "           Conv2d-16             [-1, 32, 9, 9]         100,384\n",
      "             ReLU-17             [-1, 32, 9, 9]               0\n",
      "      BatchNorm2d-18             [-1, 32, 9, 9]              64\n",
      "        MaxPool2d-19             [-1, 32, 4, 9]               0\n",
      "          Dropout-20             [-1, 32, 4, 9]               0\n",
      "           Conv2d-21              [-1, 4, 1, 9]           3,588\n",
      "          Sigmoid-22              [-1, 4, 1, 9]               0\n",
      "================================================================\n",
      "Total params: 518,564\n",
      "Trainable params: 518,564\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.20\n",
      "Params size (MB): 1.98\n",
      "Estimated Total Size (MB): 3.18\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Trying dropout after pool\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class ModelV3_1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelV3_1, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.pool = torch.nn.MaxPool2d((6, 1), stride=1)\n",
    "        \n",
    "        self.bn_1 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn_2 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn_3 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn_4 = torch.nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2d_1 = torch.nn.Conv2d(4, 64, (7, 7), padding=(3, 3))\n",
    "        self.conv2d_2 = torch.nn.Conv2d(64, 64, (7, 7), padding=(3, 3))\n",
    "        self.conv2d_3 = torch.nn.Conv2d(64, 64, (7, 7), padding=(3, 3))\n",
    "        self.conv2d_4 = torch.nn.Conv2d(64, 32, (7, 7), padding=(3, 3))\n",
    "        self.conv2d_5 = torch.nn.Conv2d(32, 4, (4, 7), padding=(0, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_manzu = x[..., 0:9]\n",
    "        x_pinzu = x[..., 9:18]\n",
    "        x_soozu = x[..., 18:27]\n",
    "        x_jihai = torch.nn.functional.pad(x[..., 27:34], (1, 1, 0, 0))\n",
    "        x = torch.stack([x_manzu, x_pinzu, x_soozu, x_jihai], dim=-3)\n",
    "        x = self.dropout(self.pool(self.bn_1(self.relu(self.conv2d_1(x)))))\n",
    "        x = self.dropout(self.pool(self.bn_2(self.relu(self.conv2d_2(x)))))\n",
    "        x = self.dropout(self.pool(self.bn_3(self.relu(self.conv2d_3(x)))))\n",
    "        x = self.dropout(self.pool(self.bn_4(self.relu(self.conv2d_4(x)))))\n",
    "        x = self.sigmoid(self.conv2d_5(x))\n",
    "        x = torch.squeeze(x, dim=-2)\n",
    "        x = torch.concat([x[..., 0, :], x[..., 1, :], x[..., 2, :], x[..., 3, 1:8]], dim=-1)\n",
    "        return x\n",
    "\n",
    "summary(ModelV3_1(), (24, 34), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c4f386d-d062-404e-afa0-51f6a702ca32",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 64, 24, 9]          12,608\n",
      "              ReLU-2            [-1, 64, 24, 9]               0\n",
      "       BatchNorm2d-3            [-1, 64, 24, 9]             128\n",
      "         MaxPool2d-4            [-1, 64, 19, 9]               0\n",
      "           Dropout-5            [-1, 64, 19, 9]               0\n",
      "            Conv2d-6            [-1, 64, 19, 9]         200,768\n",
      "              ReLU-7            [-1, 64, 19, 9]               0\n",
      "       BatchNorm2d-8            [-1, 64, 19, 9]             128\n",
      "         MaxPool2d-9            [-1, 64, 14, 9]               0\n",
      "          Dropout-10            [-1, 64, 14, 9]               0\n",
      "           Conv2d-11            [-1, 64, 14, 9]         200,768\n",
      "             ReLU-12            [-1, 64, 14, 9]               0\n",
      "      BatchNorm2d-13            [-1, 64, 14, 9]             128\n",
      "        MaxPool2d-14             [-1, 64, 9, 9]               0\n",
      "          Dropout-15             [-1, 64, 9, 9]               0\n",
      "           Conv2d-16             [-1, 32, 9, 9]         100,384\n",
      "             ReLU-17             [-1, 32, 9, 9]               0\n",
      "      BatchNorm2d-18             [-1, 32, 9, 9]              64\n",
      "        MaxPool2d-19             [-1, 32, 4, 9]               0\n",
      "          Dropout-20             [-1, 32, 4, 9]               0\n",
      "           Conv2d-21              [-1, 4, 1, 9]           3,588\n",
      "          Sigmoid-22              [-1, 4, 1, 9]               0\n",
      "================================================================\n",
      "Total params: 518,564\n",
      "Trainable params: 518,564\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.20\n",
      "Params size (MB): 1.98\n",
      "Estimated Total Size (MB): 3.18\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Increased dropout from 0.5 to 0.75\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class ModelV3_2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelV3_2, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(0.75)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.pool = torch.nn.MaxPool2d((6, 1), stride=1)\n",
    "        \n",
    "        self.bn_1 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn_2 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn_3 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn_4 = torch.nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2d_1 = torch.nn.Conv2d(4, 64, (7, 7), padding=(3, 3))\n",
    "        self.conv2d_2 = torch.nn.Conv2d(64, 64, (7, 7), padding=(3, 3))\n",
    "        self.conv2d_3 = torch.nn.Conv2d(64, 64, (7, 7), padding=(3, 3))\n",
    "        self.conv2d_4 = torch.nn.Conv2d(64, 32, (7, 7), padding=(3, 3))\n",
    "        self.conv2d_5 = torch.nn.Conv2d(32, 4, (4, 7), padding=(0, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_manzu = x[..., 0:9]\n",
    "        x_pinzu = x[..., 9:18]\n",
    "        x_soozu = x[..., 18:27]\n",
    "        x_jihai = torch.nn.functional.pad(x[..., 27:34], (1, 1, 0, 0))\n",
    "        x = torch.stack([x_manzu, x_pinzu, x_soozu, x_jihai], dim=-3)\n",
    "        x = self.dropout(self.pool(self.bn_1(self.relu(self.conv2d_1(x)))))\n",
    "        x = self.dropout(self.pool(self.bn_2(self.relu(self.conv2d_2(x)))))\n",
    "        x = self.dropout(self.pool(self.bn_3(self.relu(self.conv2d_3(x)))))\n",
    "        x = self.dropout(self.pool(self.bn_4(self.relu(self.conv2d_4(x)))))\n",
    "        x = self.sigmoid(self.conv2d_5(x))\n",
    "        x = torch.squeeze(x, dim=-2)\n",
    "        x = torch.concat([x[..., 0, :], x[..., 1, :], x[..., 2, :], x[..., 3, 1:8]], dim=-1)\n",
    "        return x\n",
    "\n",
    "summary(ModelV3_2(), (24, 34), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "631dd86d-0481-45b1-ab83-c5f6f5f457c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 64, 24, 9]          12,608\n",
      "              ReLU-2            [-1, 64, 24, 9]               0\n",
      "       BatchNorm2d-3            [-1, 64, 24, 9]             128\n",
      "           Dropout-4            [-1, 64, 24, 9]               0\n",
      "            Conv2d-5            [-1, 64, 24, 9]         200,768\n",
      "              ReLU-6            [-1, 64, 24, 9]               0\n",
      "       BatchNorm2d-7            [-1, 64, 24, 9]             128\n",
      "         MaxPool2d-8            [-1, 64, 12, 9]               0\n",
      "           Dropout-9            [-1, 64, 12, 9]               0\n",
      "           Conv2d-10            [-1, 64, 12, 9]         200,768\n",
      "             ReLU-11            [-1, 64, 12, 9]               0\n",
      "      BatchNorm2d-12            [-1, 64, 12, 9]             128\n",
      "          Dropout-13            [-1, 64, 12, 9]               0\n",
      "           Conv2d-14            [-1, 64, 12, 9]         200,768\n",
      "             ReLU-15            [-1, 64, 12, 9]               0\n",
      "      BatchNorm2d-16            [-1, 64, 12, 9]             128\n",
      "        MaxPool2d-17             [-1, 64, 6, 9]               0\n",
      "          Dropout-18             [-1, 64, 6, 9]               0\n",
      "           Conv2d-19             [-1, 32, 6, 9]         100,384\n",
      "             ReLU-20             [-1, 32, 6, 9]               0\n",
      "      BatchNorm2d-21             [-1, 32, 6, 9]              64\n",
      "          Dropout-22             [-1, 32, 6, 9]               0\n",
      "           Conv2d-23              [-1, 4, 1, 9]           5,380\n",
      "          Sigmoid-24              [-1, 4, 1, 9]               0\n",
      "================================================================\n",
      "Total params: 721,252\n",
      "Trainable params: 721,252\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.32\n",
      "Params size (MB): 2.75\n",
      "Estimated Total Size (MB): 4.07\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Changed pooling size\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class ModelV3_3(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelV3_3, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.pool = torch.nn.MaxPool2d((2, 1))\n",
    "        \n",
    "        self.bn_1 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn_2 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn_3 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn_4 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn_5 = torch.nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2d_1 = torch.nn.Conv2d(4, 64, (7, 7), padding=(3, 3))\n",
    "        self.conv2d_2 = torch.nn.Conv2d(64, 64, (7, 7), padding=(3, 3))\n",
    "        self.conv2d_3 = torch.nn.Conv2d(64, 64, (7, 7), padding=(3, 3))\n",
    "        self.conv2d_4 = torch.nn.Conv2d(64, 64, (7, 7), padding=(3, 3))\n",
    "        self.conv2d_5 = torch.nn.Conv2d(64, 32, (7, 7), padding=(3, 3))\n",
    "        self.conv2d_6 = torch.nn.Conv2d(32, 4, (6, 7), padding=(0, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_manzu = x[..., 0:9]\n",
    "        x_pinzu = x[..., 9:18]\n",
    "        x_soozu = x[..., 18:27]\n",
    "        x_jihai = torch.nn.functional.pad(x[..., 27:34], (1, 1, 0, 0))\n",
    "        x = torch.stack([x_manzu, x_pinzu, x_soozu, x_jihai], dim=-3)\n",
    "        x = self.dropout(self.bn_1(self.relu(self.conv2d_1(x))))\n",
    "        x = self.dropout(self.pool(self.bn_2(self.relu(self.conv2d_2(x)))))\n",
    "        x = self.dropout(self.bn_3(self.relu(self.conv2d_3(x))))\n",
    "        x = self.dropout(self.pool(self.bn_4(self.relu(self.conv2d_4(x)))))\n",
    "        x = self.dropout(self.bn_5(self.relu(self.conv2d_5(x))))\n",
    "        x = self.sigmoid(self.conv2d_6(x))\n",
    "        x = torch.squeeze(x, dim=-2)\n",
    "        x = torch.concat([x[..., 0, :], x[..., 1, :], x[..., 2, :], x[..., 3, 1:8]], dim=-1)\n",
    "        return x\n",
    "\n",
    "summary(ModelV3_3(), (24, 34), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bb65d5-37e1-4530-adfa-25ccff231aea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Model V4\n",
    "A modification of model V3_3, using residual networks like Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a95f0066-b017-44d3-bfb9-1975a5bce031",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 64, 24, 9]          12,608\n",
      "              ReLU-2            [-1, 64, 24, 9]               0\n",
      "       BatchNorm2d-3            [-1, 64, 24, 9]             128\n",
      "           Dropout-4            [-1, 64, 24, 9]               0\n",
      "            Conv2d-5            [-1, 64, 24, 9]         200,768\n",
      "              ReLU-6            [-1, 64, 24, 9]               0\n",
      "       BatchNorm2d-7            [-1, 64, 24, 9]             128\n",
      "         MaxPool2d-8            [-1, 64, 12, 9]               0\n",
      "           Dropout-9            [-1, 64, 12, 9]               0\n",
      "           Conv2d-10            [-1, 64, 12, 9]         200,768\n",
      "             ReLU-11            [-1, 64, 12, 9]               0\n",
      "      BatchNorm2d-12            [-1, 64, 12, 9]             128\n",
      "          Dropout-13            [-1, 64, 12, 9]               0\n",
      "           Conv2d-14            [-1, 64, 12, 9]         200,768\n",
      "             ReLU-15            [-1, 64, 12, 9]               0\n",
      "      BatchNorm2d-16            [-1, 64, 12, 9]             128\n",
      "        MaxPool2d-17             [-1, 64, 6, 9]               0\n",
      "          Dropout-18             [-1, 64, 6, 9]               0\n",
      "           Conv2d-19             [-1, 32, 6, 9]         100,384\n",
      "             ReLU-20             [-1, 32, 6, 9]               0\n",
      "      BatchNorm2d-21             [-1, 32, 6, 9]              64\n",
      "          Dropout-22             [-1, 32, 6, 9]               0\n",
      "           Conv2d-23              [-1, 4, 1, 9]           5,380\n",
      "          Sigmoid-24              [-1, 4, 1, 9]               0\n",
      "================================================================\n",
      "Total params: 721,252\n",
      "Trainable params: 721,252\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.32\n",
      "Params size (MB): 2.75\n",
      "Estimated Total Size (MB): 4.07\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class ModelV4(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelV4, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.pool = torch.nn.MaxPool2d((2, 1))\n",
    "        \n",
    "        self.bn_1 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn_2 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn_3 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn_4 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn_5 = torch.nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2d_1 = torch.nn.Conv2d(4, 64, (7, 7), padding=(3, 3))\n",
    "        self.conv2d_2 = torch.nn.Conv2d(64, 64, (7, 7), padding=(3, 3))\n",
    "        self.conv2d_3 = torch.nn.Conv2d(64, 64, (7, 7), padding=(3, 3))\n",
    "        self.conv2d_4 = torch.nn.Conv2d(64, 64, (7, 7), padding=(3, 3))\n",
    "        self.conv2d_5 = torch.nn.Conv2d(64, 32, (7, 7), padding=(3, 3))\n",
    "        self.conv2d_6 = torch.nn.Conv2d(32, 4, (6, 7), padding=(0, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_manzu = x[..., 0:9]\n",
    "        x_pinzu = x[..., 9:18]\n",
    "        x_soozu = x[..., 18:27]\n",
    "        x_jihai = torch.nn.functional.pad(x[..., 27:34], (1, 1, 0, 0))\n",
    "        x = torch.stack([x_manzu, x_pinzu, x_soozu, x_jihai], dim=-3)\n",
    "        x = self.dropout(self.bn_1(self.relu(self.conv2d_1(x))))\n",
    "        x = torch.add(x, self.bn_2(self.relu(self.conv2d_2(x))))  # Residual\n",
    "        x = self.dropout(self.pool(x))\n",
    "        x = torch.add(x, self.bn_3(self.relu(self.conv2d_3(x))))  # Residual\n",
    "        x = self.dropout(x)\n",
    "        x = torch.add(x, self.bn_4(self.relu(self.conv2d_4(x))))  # Residual\n",
    "        x = self.dropout(self.pool(x))\n",
    "        x = self.dropout(self.bn_5(self.relu(self.conv2d_5(x))))\n",
    "        x = self.sigmoid(self.conv2d_6(x))\n",
    "        x = torch.squeeze(x, dim=-2)\n",
    "        x = torch.concat([x[..., 0, :], x[..., 1, :], x[..., 2, :], x[..., 3, 1:8]], dim=-1)\n",
    "        return x\n",
    "\n",
    "summary(ModelV4(), (24, 34), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0361659-b4b5-491f-a97b-b838ecdfe040",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 64, 24, 9]             320\n",
      "            Conv2d-2            [-1, 64, 24, 9]          12,608\n",
      "       BatchNorm2d-3            [-1, 64, 24, 9]             128\n",
      "              ReLU-4            [-1, 64, 24, 9]               0\n",
      "           Dropout-5            [-1, 64, 24, 9]               0\n",
      "            Conv2d-6            [-1, 64, 24, 9]         200,768\n",
      "       BatchNorm2d-7            [-1, 64, 24, 9]             128\n",
      "              ReLU-8            [-1, 64, 24, 9]               0\n",
      "         MaxPool2d-9            [-1, 64, 12, 9]               0\n",
      "          Dropout-10            [-1, 64, 12, 9]               0\n",
      "           Conv2d-11            [-1, 64, 12, 9]           4,160\n",
      "           Conv2d-12            [-1, 64, 12, 9]         200,768\n",
      "      BatchNorm2d-13            [-1, 64, 12, 9]             128\n",
      "             ReLU-14            [-1, 64, 12, 9]               0\n",
      "          Dropout-15            [-1, 64, 12, 9]               0\n",
      "           Conv2d-16            [-1, 64, 12, 9]         200,768\n",
      "      BatchNorm2d-17            [-1, 64, 12, 9]             128\n",
      "             ReLU-18            [-1, 64, 12, 9]               0\n",
      "        MaxPool2d-19             [-1, 64, 6, 9]               0\n",
      "          Dropout-20             [-1, 64, 6, 9]               0\n",
      "           Conv2d-21              [-1, 4, 1, 9]          10,756\n",
      "          Sigmoid-22              [-1, 4, 1, 9]               0\n",
      "================================================================\n",
      "Total params: 630,660\n",
      "Trainable params: 630,660\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.42\n",
      "Params size (MB): 2.41\n",
      "Estimated Total Size (MB): 3.83\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Trying BN -> ReLU instead of ReLU -> BN\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class ModelV4_1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelV4_1, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.pool = torch.nn.MaxPool2d((2, 1))\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.bn1_1 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn1_2 = torch.nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.bn2_1 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn2_2 = torch.nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv2d1_1 = torch.nn.Conv2d(4, 64, (1, 1))\n",
    "        self.conv2d1_2 = torch.nn.Conv2d(4, 64, (7, 7), padding=(3, 3))\n",
    "        self.conv2d1_3 = torch.nn.Conv2d(64, 64, (7, 7), padding=(3, 3))\n",
    "\n",
    "        self.conv2d2_1 = torch.nn.Conv2d(64, 64, (1, 1))\n",
    "        self.conv2d2_2 = torch.nn.Conv2d(64, 64, (7, 7), padding=(3, 3))\n",
    "        self.conv2d2_3 = torch.nn.Conv2d(64, 64, (7, 7), padding=(3, 3))\n",
    "        \n",
    "        self.conv2d3 = torch.nn.Conv2d(64, 4, (6, 7), padding=(0, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_manzu = x[..., 0:9]\n",
    "        x_pinzu = x[..., 9:18]\n",
    "        x_soozu = x[..., 18:27]\n",
    "        x_jihai = torch.nn.functional.pad(x[..., 27:34], (1, 1, 0, 0))\n",
    "        x = torch.stack([x_manzu, x_pinzu, x_soozu, x_jihai], dim=-3)\n",
    "        \n",
    "        x = torch.add(\n",
    "            self.conv2d1_1(x),\n",
    "            self.conv2d1_3(self.dropout(self.relu(self.bn1_1(self.conv2d1_2(x)))))\n",
    "        )\n",
    "        x = self.dropout(self.pool(self.relu(self.bn1_2(x))))\n",
    "        \n",
    "        x = torch.add(\n",
    "            self.conv2d2_1(x),\n",
    "            self.conv2d2_3(self.dropout(self.relu(self.bn2_1(self.conv2d2_2(x)))))\n",
    "        )\n",
    "        x = self.dropout(self.pool(self.relu(self.bn2_2(x))))\n",
    "        \n",
    "        x = self.sigmoid(self.conv2d3(x))\n",
    "        x = torch.squeeze(x, dim=-2)\n",
    "        x = torch.concat([x[..., 0, :], x[..., 1, :], x[..., 2, :], x[..., 3, 1:8]], dim=-1)\n",
    "        return x\n",
    "\n",
    "summary(ModelV4_1(), (24, 34), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7807bbfe-b476-4859-b493-a983ae0910f7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 128, 24, 9]             640\n",
      "            Conv2d-2           [-1, 128, 24, 9]          25,216\n",
      "       BatchNorm2d-3           [-1, 128, 24, 9]             256\n",
      "              ReLU-4           [-1, 128, 24, 9]               0\n",
      "           Dropout-5           [-1, 128, 24, 9]               0\n",
      "            Conv2d-6           [-1, 128, 24, 9]         802,944\n",
      "       BatchNorm2d-7           [-1, 128, 24, 9]             256\n",
      "              ReLU-8           [-1, 128, 24, 9]               0\n",
      "         MaxPool2d-9           [-1, 128, 12, 9]               0\n",
      "          Dropout-10           [-1, 128, 12, 9]               0\n",
      "           Conv2d-11           [-1, 128, 12, 9]          16,512\n",
      "           Conv2d-12           [-1, 128, 12, 9]         802,944\n",
      "      BatchNorm2d-13           [-1, 128, 12, 9]             256\n",
      "             ReLU-14           [-1, 128, 12, 9]               0\n",
      "          Dropout-15           [-1, 128, 12, 9]               0\n",
      "           Conv2d-16           [-1, 128, 12, 9]         802,944\n",
      "      BatchNorm2d-17           [-1, 128, 12, 9]             256\n",
      "             ReLU-18           [-1, 128, 12, 9]               0\n",
      "        MaxPool2d-19            [-1, 128, 6, 9]               0\n",
      "          Dropout-20            [-1, 128, 6, 9]               0\n",
      "           Conv2d-21              [-1, 4, 1, 9]          21,508\n",
      "          Sigmoid-22              [-1, 4, 1, 9]               0\n",
      "================================================================\n",
      "Total params: 2,473,732\n",
      "Trainable params: 2,473,732\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.85\n",
      "Params size (MB): 9.44\n",
      "Estimated Total Size (MB): 12.29\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Increasing kernel from 64 to 128\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class ModelV4_2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelV4_2, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.pool = torch.nn.MaxPool2d((2, 1))\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.bn1_1 = torch.nn.BatchNorm2d(128)\n",
    "        self.bn1_2 = torch.nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.bn2_1 = torch.nn.BatchNorm2d(128)\n",
    "        self.bn2_2 = torch.nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv2d1_1 = torch.nn.Conv2d(4, 128, (1, 1))\n",
    "        self.conv2d1_2 = torch.nn.Conv2d(4, 128, (7, 7), padding=(3, 3))\n",
    "        self.conv2d1_3 = torch.nn.Conv2d(128, 128, (7, 7), padding=(3, 3))\n",
    "\n",
    "        self.conv2d2_1 = torch.nn.Conv2d(128, 128, (1, 1))\n",
    "        self.conv2d2_2 = torch.nn.Conv2d(128, 128, (7, 7), padding=(3, 3))\n",
    "        self.conv2d2_3 = torch.nn.Conv2d(128, 128, (7, 7), padding=(3, 3))\n",
    "        \n",
    "        self.conv2d3 = torch.nn.Conv2d(128, 4, (6, 7), padding=(0, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_manzu = x[..., 0:9]\n",
    "        x_pinzu = x[..., 9:18]\n",
    "        x_soozu = x[..., 18:27]\n",
    "        x_jihai = torch.nn.functional.pad(x[..., 27:34], (1, 1, 0, 0))\n",
    "        x = torch.stack([x_manzu, x_pinzu, x_soozu, x_jihai], dim=-3)\n",
    "        \n",
    "        x = torch.add(\n",
    "            self.conv2d1_1(x),\n",
    "            self.conv2d1_3(self.dropout(self.relu(self.bn1_1(self.conv2d1_2(x)))))\n",
    "        )\n",
    "        x = self.dropout(self.pool(self.relu(self.bn1_2(x))))\n",
    "        \n",
    "        x = torch.add(\n",
    "            self.conv2d2_1(x),\n",
    "            self.conv2d2_3(self.dropout(self.relu(self.bn2_1(self.conv2d2_2(x)))))\n",
    "        )\n",
    "        x = self.dropout(self.pool(self.relu(self.bn2_2(x))))\n",
    "        \n",
    "        x = self.sigmoid(self.conv2d3(x))\n",
    "        x = torch.squeeze(x, dim=-2)\n",
    "        x = torch.concat([x[..., 0, :], x[..., 1, :], x[..., 2, :], x[..., 3, 1:8]], dim=-1)\n",
    "        return x\n",
    "\n",
    "summary(ModelV4_2(), (24, 34), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9a78a82-671c-48d9-abf6-4907475624c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 64, 24, 9]             320\n",
      "            Conv2d-2            [-1, 64, 24, 9]          12,608\n",
      "       BatchNorm2d-3            [-1, 64, 24, 9]             128\n",
      "              ReLU-4            [-1, 64, 24, 9]               0\n",
      "           Dropout-5            [-1, 64, 24, 9]               0\n",
      "            Conv2d-6            [-1, 64, 24, 9]         200,768\n",
      "       BatchNorm2d-7            [-1, 64, 24, 9]             128\n",
      "              ReLU-8            [-1, 64, 24, 9]               0\n",
      "         MaxPool2d-9            [-1, 64, 12, 9]               0\n",
      "          Dropout-10            [-1, 64, 12, 9]               0\n",
      "           Conv2d-11            [-1, 64, 12, 9]           4,160\n",
      "           Conv2d-12            [-1, 64, 12, 9]         200,768\n",
      "      BatchNorm2d-13            [-1, 64, 12, 9]             128\n",
      "             ReLU-14            [-1, 64, 12, 9]               0\n",
      "          Dropout-15            [-1, 64, 12, 9]               0\n",
      "           Conv2d-16            [-1, 64, 12, 9]         200,768\n",
      "      BatchNorm2d-17            [-1, 64, 12, 9]             128\n",
      "             ReLU-18            [-1, 64, 12, 9]               0\n",
      "          Dropout-19            [-1, 64, 12, 9]               0\n",
      "           Conv2d-20            [-1, 64, 12, 9]           4,160\n",
      "           Conv2d-21            [-1, 64, 12, 9]         200,768\n",
      "      BatchNorm2d-22            [-1, 64, 12, 9]             128\n",
      "             ReLU-23            [-1, 64, 12, 9]               0\n",
      "          Dropout-24            [-1, 64, 12, 9]               0\n",
      "           Conv2d-25            [-1, 64, 12, 9]         200,768\n",
      "      BatchNorm2d-26            [-1, 64, 12, 9]             128\n",
      "             ReLU-27            [-1, 64, 12, 9]               0\n",
      "        MaxPool2d-28             [-1, 64, 6, 9]               0\n",
      "          Dropout-29             [-1, 64, 6, 9]               0\n",
      "           Conv2d-30              [-1, 4, 1, 9]          10,756\n",
      "          Sigmoid-31              [-1, 4, 1, 9]               0\n",
      "================================================================\n",
      "Total params: 1,036,612\n",
      "Trainable params: 1,036,612\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.90\n",
      "Params size (MB): 3.95\n",
      "Estimated Total Size (MB): 5.86\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Increasing model depth from v4_1\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class ModelV4_3(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelV4_3, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.pool = torch.nn.MaxPool2d((2, 1))\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.bn1_1 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn1_2 = torch.nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.bn2_1 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn2_2 = torch.nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.bn3_1 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn3_2 = torch.nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv2d1_1 = torch.nn.Conv2d(4, 64, (1, 1))\n",
    "        self.conv2d1_2 = torch.nn.Conv2d(4, 64, (7, 7), padding=(3, 3))\n",
    "        self.conv2d1_3 = torch.nn.Conv2d(64, 64, (7, 7), padding=(3, 3))\n",
    "\n",
    "        self.conv2d2_1 = torch.nn.Conv2d(64, 64, (1, 1))\n",
    "        self.conv2d2_2 = torch.nn.Conv2d(64, 64, (7, 7), padding=(3, 3))\n",
    "        self.conv2d2_3 = torch.nn.Conv2d(64, 64, (7, 7), padding=(3, 3))\n",
    "\n",
    "        self.conv2d3_1 = torch.nn.Conv2d(64, 64, (1, 1))\n",
    "        self.conv2d3_2 = torch.nn.Conv2d(64, 64, (7, 7), padding=(3, 3))\n",
    "        self.conv2d3_3 = torch.nn.Conv2d(64, 64, (7, 7), padding=(3, 3))\n",
    "        \n",
    "        self.conv2d4 = torch.nn.Conv2d(64, 4, (6, 7), padding=(0, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_manzu = x[..., 0:9]\n",
    "        x_pinzu = x[..., 9:18]\n",
    "        x_soozu = x[..., 18:27]\n",
    "        x_jihai = torch.nn.functional.pad(x[..., 27:34], (1, 1, 0, 0))\n",
    "        x = torch.stack([x_manzu, x_pinzu, x_soozu, x_jihai], dim=-3)\n",
    "        \n",
    "        x = torch.add(\n",
    "            self.conv2d1_1(x),\n",
    "            self.conv2d1_3(self.dropout(self.relu(self.bn1_1(self.conv2d1_2(x)))))\n",
    "        )\n",
    "        x = self.dropout(self.pool(self.relu(self.bn1_2(x))))\n",
    "        \n",
    "        x = torch.add(\n",
    "            self.conv2d2_1(x),\n",
    "            self.conv2d2_3(self.dropout(self.relu(self.bn2_1(self.conv2d2_2(x)))))\n",
    "        )\n",
    "        x = self.dropout(self.relu(self.bn2_2(x)))\n",
    "        x = torch.add(\n",
    "            self.conv2d3_1(x),\n",
    "            self.conv2d3_3(self.dropout(self.relu(self.bn3_1(self.conv2d3_2(x)))))\n",
    "        )\n",
    "        x = self.dropout(self.pool(self.relu(self.bn3_2(x))))\n",
    "        \n",
    "        x = self.sigmoid(self.conv2d4(x))\n",
    "        x = torch.squeeze(x, dim=-2)\n",
    "        x = torch.concat([x[..., 0, :], x[..., 1, :], x[..., 2, :], x[..., 3, 1:8]], dim=-1)\n",
    "        return x\n",
    "\n",
    "summary(ModelV4_3(), (24, 34), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6582f93-2ad5-42bb-bcb6-3b72e33a2f72",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Model V5\n",
    "A modification of model V4 and V3, using inception networks instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "318c8d2c-810a-4b8d-9fb7-a1644a3d35ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 16, 24, 9]              80\n",
      "            Conv2d-2            [-1, 32, 24, 9]             160\n",
      "              ReLU-3            [-1, 32, 24, 9]               0\n",
      "            Conv2d-4            [-1, 32, 24, 9]          21,536\n",
      "            Conv2d-5            [-1, 32, 24, 9]             160\n",
      "              ReLU-6            [-1, 32, 24, 9]               0\n",
      "            Conv2d-7            [-1, 32, 24, 9]          35,872\n",
      "            Conv2d-8            [-1, 48, 24, 9]             240\n",
      "              ReLU-9            [-1, 48, 24, 9]               0\n",
      "           Conv2d-10            [-1, 48, 24, 9]         112,944\n",
      "      BatchNorm2d-11           [-1, 128, 24, 9]             256\n",
      "             ReLU-12           [-1, 128, 24, 9]               0\n",
      "        MaxPool2d-13           [-1, 128, 12, 9]               0\n",
      "          Dropout-14           [-1, 128, 12, 9]               0\n",
      "           Conv2d-15            [-1, 24, 12, 9]           3,096\n",
      "           Conv2d-16            [-1, 48, 12, 9]           6,192\n",
      "             ReLU-17            [-1, 48, 12, 9]               0\n",
      "           Conv2d-18            [-1, 48, 12, 9]          48,432\n",
      "           Conv2d-19            [-1, 48, 12, 9]           6,192\n",
      "             ReLU-20            [-1, 48, 12, 9]               0\n",
      "           Conv2d-21            [-1, 48, 12, 9]          80,688\n",
      "           Conv2d-22            [-1, 64, 12, 9]           8,256\n",
      "             ReLU-23            [-1, 64, 12, 9]               0\n",
      "           Conv2d-24            [-1, 64, 12, 9]         200,768\n",
      "      BatchNorm2d-25           [-1, 184, 12, 9]             368\n",
      "             ReLU-26           [-1, 184, 12, 9]               0\n",
      "        MaxPool2d-27            [-1, 184, 6, 9]               0\n",
      "          Dropout-28            [-1, 184, 6, 9]               0\n",
      "           Conv2d-29              [-1, 4, 1, 9]          30,916\n",
      "          Sigmoid-30              [-1, 4, 1, 9]               0\n",
      "================================================================\n",
      "Total params: 556,156\n",
      "Trainable params: 556,156\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.08\n",
      "Params size (MB): 2.12\n",
      "Estimated Total Size (MB): 4.21\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class ModelV5(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelV5, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.pool = torch.nn.MaxPool2d((2, 1))\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.bn1 = torch.nn.BatchNorm2d(128)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(184)\n",
    "\n",
    "        self.conv2d1a1 = torch.nn.Conv2d(4, 16, (1, 1))\n",
    "        self.conv2d1b1 = torch.nn.Conv2d(4, 32, (1, 1))\n",
    "        self.conv2d1b2 = torch.nn.Conv2d(32, 32, (3, 7), padding=(1, 3))\n",
    "        self.conv2d1c1 = torch.nn.Conv2d(4, 32, (1, 1))\n",
    "        self.conv2d1c2 = torch.nn.Conv2d(32, 32, (5, 7), padding=(2, 3))\n",
    "        self.conv2d1d1 = torch.nn.Conv2d(4, 48, (1, 1))\n",
    "        self.conv2d1d2 = torch.nn.Conv2d(48, 48, (7, 7), padding=(3, 3))\n",
    "\n",
    "        self.conv2d2a1 = torch.nn.Conv2d(128, 24, (1, 1))\n",
    "        self.conv2d2b1 = torch.nn.Conv2d(128, 48, (1, 1))\n",
    "        self.conv2d2b2 = torch.nn.Conv2d(48, 48, (3, 7), padding=(1, 3))\n",
    "        self.conv2d2c1 = torch.nn.Conv2d(128, 48, (1, 1))\n",
    "        self.conv2d2c2 = torch.nn.Conv2d(48, 48, (5, 7), padding=(2, 3))\n",
    "        self.conv2d2d1 = torch.nn.Conv2d(128, 64, (1, 1))\n",
    "        self.conv2d2d2 = torch.nn.Conv2d(64, 64, (7, 7), padding=(3, 3))\n",
    "        \n",
    "        self.conv2d3 = torch.nn.Conv2d(184, 4, (6, 7), padding=(0, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_manzu = x[..., 0:9]\n",
    "        x_pinzu = x[..., 9:18]\n",
    "        x_soozu = x[..., 18:27]\n",
    "        x_jihai = torch.nn.functional.pad(x[..., 27:34], (1, 1, 0, 0))\n",
    "        x = torch.stack([x_manzu, x_pinzu, x_soozu, x_jihai], dim=-3)\n",
    "        x = torch.cat([\n",
    "            self.conv2d1a1(x), \n",
    "            self.conv2d1b2(self.relu(self.conv2d1b1(x))),\n",
    "            self.conv2d1c2(self.relu(self.conv2d1c1(x))),\n",
    "            self.conv2d1d2(self.relu(self.conv2d1d1(x))),\n",
    "        ], dim=-3)\n",
    "        x = self.dropout(self.pool(self.relu(self.bn1(x))))\n",
    "        x = torch.cat([\n",
    "            self.conv2d2a1(x), \n",
    "            self.conv2d2b2(self.relu(self.conv2d2b1(x))),\n",
    "            self.conv2d2c2(self.relu(self.conv2d2c1(x))),\n",
    "            self.conv2d2d2(self.relu(self.conv2d2d1(x))),\n",
    "        ], dim=-3)\n",
    "        x = self.dropout(self.pool(self.relu(self.bn2(x))))\n",
    "        x = self.sigmoid(self.conv2d3(x))\n",
    "        x = torch.squeeze(x, dim=-2)\n",
    "        x = torch.concat([x[..., 0, :], x[..., 1, :], x[..., 2, :], x[..., 3, 1:8]], dim=-1)\n",
    "        return x\n",
    "\n",
    "summary(ModelV5(), (24, 34), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4744d-782d-48f2-b908-bfdfd9b5679d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Model V6\n",
    "Recoding the model from V4_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "740fbe95-79ae-44d4-8c12-7ca6a2a3687f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 64, 24, 9]             320\n",
      "            Conv2d-2            [-1, 64, 24, 9]          12,608\n",
      "       BatchNorm2d-3            [-1, 64, 24, 9]             128\n",
      "              ReLU-4            [-1, 64, 24, 9]               0\n",
      "           Dropout-5            [-1, 64, 24, 9]               0\n",
      "            Conv2d-6            [-1, 64, 24, 9]         200,768\n",
      "       BatchNorm2d-7            [-1, 64, 24, 9]             128\n",
      "              ReLU-8            [-1, 64, 24, 9]               0\n",
      "         MaxPool2d-9            [-1, 64, 12, 9]               0\n",
      "          Dropout-10            [-1, 64, 12, 9]               0\n",
      "           Conv2d-11            [-1, 64, 12, 9]           4,160\n",
      "           Conv2d-12            [-1, 64, 12, 9]         200,768\n",
      "      BatchNorm2d-13            [-1, 64, 12, 9]             128\n",
      "             ReLU-14            [-1, 64, 12, 9]               0\n",
      "          Dropout-15            [-1, 64, 12, 9]               0\n",
      "           Conv2d-16            [-1, 64, 12, 9]         200,768\n",
      "      BatchNorm2d-17            [-1, 64, 12, 9]             128\n",
      "             ReLU-18            [-1, 64, 12, 9]               0\n",
      "          Dropout-19            [-1, 64, 12, 9]               0\n",
      "           Conv2d-20            [-1, 64, 12, 9]           4,160\n",
      "           Conv2d-21            [-1, 64, 12, 9]         200,768\n",
      "      BatchNorm2d-22            [-1, 64, 12, 9]             128\n",
      "             ReLU-23            [-1, 64, 12, 9]               0\n",
      "          Dropout-24            [-1, 64, 12, 9]               0\n",
      "           Conv2d-25            [-1, 64, 12, 9]         200,768\n",
      "      BatchNorm2d-26            [-1, 64, 12, 9]             128\n",
      "             ReLU-27            [-1, 64, 12, 9]               0\n",
      "        MaxPool2d-28             [-1, 64, 6, 9]               0\n",
      "          Dropout-29             [-1, 64, 6, 9]               0\n",
      "           Conv2d-30              [-1, 4, 1, 9]          10,756\n",
      "          Sigmoid-31              [-1, 4, 1, 9]               0\n",
      "================================================================\n",
      "Total params: 1,036,612\n",
      "Trainable params: 1,036,612\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.90\n",
      "Params size (MB): 3.95\n",
      "Estimated Total Size (MB): 5.86\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class ModelV6(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelV6, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.pool = torch.nn.MaxPool2d((2, 1))\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "        self.blocks = (\n",
    "            (\"block1\", 4, 64, 2, (7, 7), True),\n",
    "            (\"block2\", 64, 64, 2, (7, 7), False),\n",
    "            (\"block3\", 64, 64, 2, (7, 7), True),\n",
    "        )\n",
    "        for block_args in self.blocks:\n",
    "            self._create_block(*block_args)\n",
    "        \n",
    "        self.conv_final = torch.nn.Conv2d(64, 4, (6, 7), padding=(0, 3))\n",
    "\n",
    "    def _create_block(self, prefix, in_layers, out_layers, depth, kernel_size, downsize):\n",
    "        padding = tuple(i // 2 for i in kernel_size)\n",
    "        setattr(self, f\"{prefix}_conv_res\", torch.nn.Conv2d(in_layers, out_layers, (1, 1)))\n",
    "        for sublayer in range(depth):\n",
    "            setattr(self, f\"{prefix}_conv_{sublayer}\", \n",
    "                    torch.nn.Conv2d(\n",
    "                        in_layers if sublayer == 0 else out_layers, \n",
    "                        out_layers, kernel_size, padding=padding))\n",
    "            setattr(self, f\"{prefix}_bn_{sublayer}\", torch.nn.BatchNorm2d(out_layers))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_manzu = x[..., 0:9]\n",
    "        x_pinzu = x[..., 9:18]\n",
    "        x_soozu = x[..., 18:27]\n",
    "        x_jihai = torch.nn.functional.pad(x[..., 27:34], (1, 1, 0, 0))\n",
    "        x = torch.stack([x_manzu, x_pinzu, x_soozu, x_jihai], dim=-3)\n",
    "        for prefix, depth, downsize in map(lambda t: (t[0], t[3], t[5]), self.blocks):\n",
    "            x_res = getattr(self, f\"{prefix}_conv_res\")(x)\n",
    "            for sublayer in range(depth):\n",
    "                if sublayer == (depth - 1):  # Final layer\n",
    "                    x = getattr(self, f\"{prefix}_conv_{sublayer}\")(x)\n",
    "                    x = torch.add(x, x_res)\n",
    "                    x = getattr(self, f\"{prefix}_bn_{sublayer}\")(x)\n",
    "                    x = self.relu(x)\n",
    "                    if downsize:\n",
    "                        x = self.pool(x)\n",
    "                    x = self.dropout(x)\n",
    "                else:\n",
    "                    x = getattr(self, f\"{prefix}_conv_{sublayer}\")(x)\n",
    "                    x = getattr(self, f\"{prefix}_bn_{sublayer}\")(x)\n",
    "                    x = self.relu(x)\n",
    "                    x = self.dropout(x)\n",
    "        x = self.sigmoid(self.conv_final(x))\n",
    "        x = torch.squeeze(x, dim=-2)\n",
    "        x = torch.concat([x[..., 0, :], x[..., 1, :], x[..., 2, :], x[..., 3, 1:8]], dim=-1)\n",
    "        return x\n",
    "\n",
    "summary(ModelV6(), (24, 34), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87c5e9b3-9c8b-415c-b746-6b70901dfe5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 64, 24, 9]             320\n",
      "            Conv2d-2            [-1, 64, 24, 9]          12,608\n",
      "       BatchNorm2d-3            [-1, 64, 24, 9]             128\n",
      "              ReLU-4            [-1, 64, 24, 9]               0\n",
      "           Dropout-5            [-1, 64, 24, 9]               0\n",
      "            Conv2d-6            [-1, 64, 24, 9]         200,768\n",
      "       BatchNorm2d-7            [-1, 64, 24, 9]             128\n",
      "              ReLU-8            [-1, 64, 24, 9]               0\n",
      "           Dropout-9            [-1, 64, 24, 9]               0\n",
      "           Conv2d-10            [-1, 64, 24, 9]           4,160\n",
      "           Conv2d-11            [-1, 64, 24, 9]         200,768\n",
      "      BatchNorm2d-12            [-1, 64, 24, 9]             128\n",
      "             ReLU-13            [-1, 64, 24, 9]               0\n",
      "          Dropout-14            [-1, 64, 24, 9]               0\n",
      "           Conv2d-15            [-1, 64, 24, 9]         200,768\n",
      "      BatchNorm2d-16            [-1, 64, 24, 9]             128\n",
      "             ReLU-17            [-1, 64, 24, 9]               0\n",
      "        MaxPool2d-18            [-1, 64, 12, 9]               0\n",
      "          Dropout-19            [-1, 64, 12, 9]               0\n",
      "           Conv2d-20            [-1, 64, 12, 9]           4,160\n",
      "           Conv2d-21            [-1, 64, 12, 9]         200,768\n",
      "      BatchNorm2d-22            [-1, 64, 12, 9]             128\n",
      "             ReLU-23            [-1, 64, 12, 9]               0\n",
      "          Dropout-24            [-1, 64, 12, 9]               0\n",
      "           Conv2d-25            [-1, 64, 12, 9]         200,768\n",
      "      BatchNorm2d-26            [-1, 64, 12, 9]             128\n",
      "             ReLU-27            [-1, 64, 12, 9]               0\n",
      "          Dropout-28            [-1, 64, 12, 9]               0\n",
      "           Conv2d-29            [-1, 64, 12, 9]           4,160\n",
      "           Conv2d-30            [-1, 64, 12, 9]         200,768\n",
      "      BatchNorm2d-31            [-1, 64, 12, 9]             128\n",
      "             ReLU-32            [-1, 64, 12, 9]               0\n",
      "          Dropout-33            [-1, 64, 12, 9]               0\n",
      "           Conv2d-34            [-1, 64, 12, 9]         200,768\n",
      "      BatchNorm2d-35            [-1, 64, 12, 9]             128\n",
      "             ReLU-36            [-1, 64, 12, 9]               0\n",
      "        MaxPool2d-37             [-1, 64, 6, 9]               0\n",
      "          Dropout-38             [-1, 64, 6, 9]               0\n",
      "           Conv2d-39             [-1, 64, 6, 9]           4,160\n",
      "           Conv2d-40             [-1, 64, 6, 9]         200,768\n",
      "      BatchNorm2d-41             [-1, 64, 6, 9]             128\n",
      "             ReLU-42             [-1, 64, 6, 9]               0\n",
      "          Dropout-43             [-1, 64, 6, 9]               0\n",
      "           Conv2d-44             [-1, 64, 6, 9]         200,768\n",
      "      BatchNorm2d-45             [-1, 64, 6, 9]             128\n",
      "             ReLU-46             [-1, 64, 6, 9]               0\n",
      "          Dropout-47             [-1, 64, 6, 9]               0\n",
      "           Conv2d-48              [-1, 4, 1, 9]          10,756\n",
      "          Sigmoid-49              [-1, 4, 1, 9]               0\n",
      "================================================================\n",
      "Total params: 1,848,516\n",
      "Trainable params: 1,848,516\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 3.09\n",
      "Params size (MB): 7.05\n",
      "Estimated Total Size (MB): 10.14\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Increasing layers\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class ModelV6_1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelV6_1, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.pool = torch.nn.MaxPool2d((2, 1))\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "        self.blocks = (\n",
    "            (\"block1a\", 4, 64, 2, (7, 7), False),\n",
    "            (\"block1b\", 64, 64, 2, (7, 7), True),\n",
    "            (\"block2a\", 64, 64, 2, (7, 7), False),\n",
    "            (\"block2b\", 64, 64, 2, (7, 7), True),\n",
    "            (\"block3a\", 64, 64, 2, (7, 7), False),\n",
    "        )\n",
    "        for block_args in self.blocks:\n",
    "            self._create_block(*block_args)\n",
    "        \n",
    "        self.conv_final = torch.nn.Conv2d(64, 4, (6, 7), padding=(0, 3))\n",
    "\n",
    "    def _create_block(self, prefix, in_layers, out_layers, depth, kernel_size, downsize):\n",
    "        padding = tuple(i // 2 for i in kernel_size)\n",
    "        setattr(self, f\"{prefix}_conv_res\", torch.nn.Conv2d(in_layers, out_layers, (1, 1)))\n",
    "        for sublayer in range(depth):\n",
    "            setattr(self, f\"{prefix}_conv_{sublayer}\", \n",
    "                    torch.nn.Conv2d(\n",
    "                        in_layers if sublayer == 0 else out_layers, \n",
    "                        out_layers, kernel_size, padding=padding))\n",
    "            setattr(self, f\"{prefix}_bn_{sublayer}\", torch.nn.BatchNorm2d(out_layers))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_manzu = x[..., 0:9]\n",
    "        x_pinzu = x[..., 9:18]\n",
    "        x_soozu = x[..., 18:27]\n",
    "        x_jihai = torch.nn.functional.pad(x[..., 27:34], (1, 1, 0, 0))\n",
    "        x = torch.stack([x_manzu, x_pinzu, x_soozu, x_jihai], dim=-3)\n",
    "        for prefix, depth, downsize in map(lambda t: (t[0], t[3], t[5]), self.blocks):\n",
    "            x_res = getattr(self, f\"{prefix}_conv_res\")(x)\n",
    "            for sublayer in range(depth):\n",
    "                if sublayer == (depth - 1):  # Final layer\n",
    "                    x = getattr(self, f\"{prefix}_conv_{sublayer}\")(x)\n",
    "                    x = torch.add(x, x_res)\n",
    "                    x = getattr(self, f\"{prefix}_bn_{sublayer}\")(x)\n",
    "                    x = self.relu(x)\n",
    "                    if downsize:\n",
    "                        x = self.pool(x)\n",
    "                    x = self.dropout(x)\n",
    "                else:\n",
    "                    x = getattr(self, f\"{prefix}_conv_{sublayer}\")(x)\n",
    "                    x = getattr(self, f\"{prefix}_bn_{sublayer}\")(x)\n",
    "                    x = self.relu(x)\n",
    "                    x = self.dropout(x)\n",
    "        x = self.sigmoid(self.conv_final(x))\n",
    "        x = torch.squeeze(x, dim=-2)\n",
    "        x = torch.concat([x[..., 0, :], x[..., 1, :], x[..., 2, :], x[..., 3, 1:8]], dim=-1)\n",
    "        return x\n",
    "\n",
    "summary(ModelV6_1(), (24, 34), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afee5c97-6cd0-4062-ae2e-63bfed67ecd4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a220252d-9d2f-426a-829a-423683c7c288",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-22 19:38:52.340627: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-22 19:38:52.340660: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-22 19:38:52.341327: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-22 19:38:52.346030: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-22 19:38:52.939735: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Epoch 1/100: 100%|████████████████████████| 1808/1808 [01:06<00:00, 27.22it/s, loss=6.093]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:07<00:00, 44.28it/s, loss=6.071]\n",
      "Epoch 2/100: 100%|████████████████████████| 1808/1808 [01:04<00:00, 27.98it/s, loss=6.053]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:07<00:00, 43.65it/s, loss=6.025]\n",
      "Epoch 3/100: 100%|████████████████████████| 1808/1808 [01:04<00:00, 28.05it/s, loss=6.024]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:07<00:00, 44.42it/s, loss=6.011]\n",
      "Epoch 4/100: 100%|████████████████████████| 1808/1808 [01:04<00:00, 28.17it/s, loss=6.003]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 45.44it/s, loss=5.979]\n",
      "Epoch 5/100: 100%|████████████████████████| 1808/1808 [01:04<00:00, 28.20it/s, loss=5.975]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:07<00:00, 44.10it/s, loss=5.949]\n",
      "Epoch 6/100: 100%|████████████████████████| 1808/1808 [01:04<00:00, 28.02it/s, loss=5.946]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:07<00:00, 44.34it/s, loss=5.931]\n",
      "Epoch 7/100: 100%|████████████████████████| 1808/1808 [01:03<00:00, 28.39it/s, loss=5.929]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:07<00:00, 44.32it/s, loss=5.925]\n",
      "Epoch 8/100: 100%|████████████████████████| 1808/1808 [01:04<00:00, 28.19it/s, loss=5.918]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 46.94it/s, loss=5.911]\n",
      "Epoch 9/100: 100%|████████████████████████| 1808/1808 [01:03<00:00, 28.54it/s, loss=5.910]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 46.91it/s, loss=5.904]\n",
      "Epoch 10/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 28.07it/s, loss=5.900]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 47.22it/s, loss=5.892]\n",
      "Epoch 11/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 28.09it/s, loss=5.894]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 46.81it/s, loss=5.889]\n",
      "Epoch 12/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 28.22it/s, loss=5.890]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 44.91it/s, loss=5.886]\n",
      "Epoch 13/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 28.22it/s, loss=5.887]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 46.37it/s, loss=5.887]\n",
      "Epoch 14/100: 100%|███████████████████████| 1808/1808 [01:03<00:00, 28.38it/s, loss=5.885]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 46.60it/s, loss=5.886]\n",
      "Epoch 15/100: 100%|███████████████████████| 1808/1808 [01:03<00:00, 28.48it/s, loss=5.883]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 46.74it/s, loss=5.884]\n",
      "Epoch 16/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 28.19it/s, loss=5.881]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 46.05it/s, loss=5.885]\n",
      "Epoch 17/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 28.21it/s, loss=5.880]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 45.88it/s, loss=5.885]\n",
      "Epoch 18/100: 100%|███████████████████████| 1808/1808 [01:03<00:00, 28.36it/s, loss=5.878]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 47.32it/s, loss=5.885]\n",
      "Epoch 19/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 27.91it/s, loss=5.877]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 46.14it/s, loss=5.884]\n",
      "Epoch 20/100: 100%|███████████████████████| 1808/1808 [01:03<00:00, 28.41it/s, loss=5.877]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 45.38it/s, loss=5.885]\n",
      "Epoch 21/100: 100%|███████████████████████| 1808/1808 [01:03<00:00, 28.48it/s, loss=5.875]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 47.35it/s, loss=5.884]\n",
      "Epoch 22/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 28.02it/s, loss=5.875]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 45.99it/s, loss=5.887]\n",
      "Epoch 23/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 28.23it/s, loss=5.874]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 48.37it/s, loss=5.884]\n",
      "Epoch 24/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 28.03it/s, loss=5.873]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 46.39it/s, loss=5.884]\n",
      "Epoch 25/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 28.15it/s, loss=5.872]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 46.38it/s, loss=5.885]\n",
      "Epoch 26/100: 100%|███████████████████████| 1808/1808 [01:03<00:00, 28.32it/s, loss=5.867]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 47.41it/s, loss=5.883]\n",
      "Epoch 27/100: 100%|███████████████████████| 1808/1808 [01:03<00:00, 28.34it/s, loss=5.866]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 46.69it/s, loss=5.882]\n",
      "Epoch 28/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 28.01it/s, loss=5.865]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:07<00:00, 44.68it/s, loss=5.883]\n",
      "Epoch 29/100: 100%|███████████████████████| 1808/1808 [01:03<00:00, 28.34it/s, loss=5.864]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 45.67it/s, loss=5.882]\n",
      "Epoch 30/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 28.17it/s, loss=5.862]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 45.58it/s, loss=5.882]\n",
      "Epoch 31/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 28.06it/s, loss=5.863]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 46.03it/s, loss=5.883]\n",
      "Epoch 32/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 28.15it/s, loss=5.861]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 46.69it/s, loss=5.884]\n",
      "Epoch 33/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 28.20it/s, loss=5.861]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 45.31it/s, loss=5.882]\n",
      "Epoch 34/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 27.89it/s, loss=5.860]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 45.50it/s, loss=5.885]\n",
      "Epoch 35/100: 100%|███████████████████████| 1808/1808 [01:05<00:00, 27.80it/s, loss=5.860]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 47.98it/s, loss=5.884]\n",
      "Epoch 36/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 28.02it/s, loss=5.859]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 48.09it/s, loss=5.884]\n",
      "Epoch 37/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 27.90it/s, loss=5.857]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 46.53it/s, loss=5.885]\n",
      "Epoch 38/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 28.09it/s, loss=5.858]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:07<00:00, 44.56it/s, loss=5.886]\n",
      "Epoch 39/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 28.03it/s, loss=5.857]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 46.69it/s, loss=5.884]\n",
      "Epoch 40/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 27.88it/s, loss=5.857]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 46.22it/s, loss=5.883]\n",
      "Epoch 41/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 27.85it/s, loss=5.855]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 45.12it/s, loss=5.886]\n",
      "Epoch 42/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 28.05it/s, loss=5.855]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 45.41it/s, loss=5.884]\n",
      "Epoch 43/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 27.87it/s, loss=5.853]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 45.85it/s, loss=5.885]\n",
      "Epoch 44/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 27.94it/s, loss=5.853]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:07<00:00, 44.70it/s, loss=5.885]\n",
      "Epoch 45/100: 100%|███████████████████████| 1808/1808 [01:02<00:00, 28.80it/s, loss=5.854]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 46.56it/s, loss=5.884]\n",
      "Epoch 46/100: 100%|███████████████████████| 1808/1808 [01:05<00:00, 27.71it/s, loss=5.852]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:07<00:00, 43.44it/s, loss=5.885]\n",
      "Epoch 47/100: 100%|███████████████████████| 1808/1808 [01:05<00:00, 27.40it/s, loss=5.853]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:07<00:00, 44.41it/s, loss=5.884]\n",
      "Epoch 48/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 28.25it/s, loss=5.852]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 46.52it/s, loss=5.884]\n",
      "Epoch 49/100: 100%|███████████████████████| 1808/1808 [01:03<00:00, 28.44it/s, loss=5.852]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 46.92it/s, loss=5.884]\n",
      "Epoch 50/100: 100%|███████████████████████| 1808/1808 [01:03<00:00, 28.43it/s, loss=5.851]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 46.51it/s, loss=5.885]\n",
      "Epoch 51/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 27.89it/s, loss=5.849]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 45.48it/s, loss=5.882]\n",
      "Epoch 52/100: 100%|███████████████████████| 1808/1808 [01:03<00:00, 28.33it/s, loss=5.847]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 46.22it/s, loss=5.885]\n",
      "Epoch 53/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 27.86it/s, loss=5.846]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:07<00:00, 43.02it/s, loss=5.885]\n",
      "Epoch 54/100: 100%|███████████████████████| 1808/1808 [01:05<00:00, 27.67it/s, loss=5.846]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 47.25it/s, loss=5.885]\n",
      "Epoch 55/100: 100%|███████████████████████| 1808/1808 [01:02<00:00, 28.72it/s, loss=5.845]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 46.65it/s, loss=5.884]\n",
      "Epoch 56/100: 100%|███████████████████████| 1808/1808 [01:05<00:00, 27.73it/s, loss=5.845]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 46.16it/s, loss=5.885]\n",
      "Epoch 57/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 28.00it/s, loss=5.845]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:07<00:00, 44.37it/s, loss=5.886]\n",
      "Epoch 58/100: 100%|███████████████████████| 1808/1808 [01:05<00:00, 27.71it/s, loss=5.844]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:07<00:00, 44.51it/s, loss=5.884]\n",
      "Epoch 59/100: 100%|███████████████████████| 1808/1808 [01:04<00:00, 27.97it/s, loss=5.844]\n",
      "Test: 100%|█████████████████████████████████| 313/313 [00:06<00:00, 45.93it/s, loss=5.885]\n",
      "Epoch 60/100:  31%|███████▌                | 567/1808 [00:20<00:43, 28.38it/s, loss=5.842]"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from collections import deque\n",
    "import datetime\n",
    "import tqdm\n",
    "\n",
    "EPOCHS = 100\n",
    "RUN_PATH = \"runs/riichi-dsv01-mv06_1\"\n",
    "\n",
    "timestamp = datetime.datetime.today().strftime(\"%Y%m%d_%H%M%S\")\n",
    "train_writer = SummaryWriter(f\"{RUN_PATH}/{timestamp}/train\")\n",
    "test_writer = SummaryWriter(f\"{RUN_PATH}/{timestamp}/test\")\n",
    "\n",
    "model = ModelV6_1()\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.to(\"cuda\")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.5)\n",
    "loss_deque = deque(maxlen=len(train_dl))\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    pbar = tqdm.tqdm(\n",
    "        range(len(train_dl)), \n",
    "        desc=f\"Epoch {epoch+1}/{EPOCHS}\", \n",
    "        position=0, leave=True, ncols=90)\n",
    "    \n",
    "    model.train(True)\n",
    "    for i, (x, y) in enumerate(train_dl):\n",
    "        x, y = x.to(\"cuda\"), y.to(\"cuda\")\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_deque.append(loss.item())\n",
    "        train_writer.add_scalar(\"loss\", loss.item(), epoch * len(train_dl) + i)\n",
    "        pbar.set_postfix({\"loss\": f\"{sum(loss_deque) / len(loss_deque):.3f}\"})\n",
    "        pbar.update()\n",
    "    scheduler.step()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    model.eval()\n",
    "    pbar = tqdm.tqdm(\n",
    "        range(len(test_dl)), desc=\"Test\", \n",
    "        position=0, leave=True, ncols=90\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(test_dl):\n",
    "            x, y = x.to(\"cuda\"), y.to(\"cuda\")\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            running_loss += loss.item()\n",
    "            pbar.set_postfix({\"loss\": f\"{running_loss / (i + 1):.3f}\"})\n",
    "            pbar.update()\n",
    "        test_writer.add_scalar(\"loss\", running_loss / len(test_dl), (epoch + 1) * len(train_dl))\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5e0077-9179-49d6-bb7b-fa97b5600e37",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "256210bc-8f28-4e75-895a-60601f4e09cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "def arr2mjutf8(x, pred, y=None):\n",
    "    mj_list_utf8 = [\n",
    "        \"🀇\",\"🀈\",\"🀉\",\"🀊\",\"🀋\",\"🀌\",\"🀍\",\"🀎\",\"🀏\",\n",
    "        \"🀙\",\"🀚\",\"🀛\",\"🀜\",\"🀝\",\"🀞\",\"🀟\",\"🀠\",\"🀡\",\n",
    "        \"🀐\",\"🀑\",\"🀒\",\"🀓\",\"🀔\",\"🀕\",\"🀖\",\"🀗\",\"🀘\",\n",
    "        \"🀀\",\"🀁\",\"🀂\",\"🀃\",\"🀆\",\"🀅\",\"🀄︎\"]\n",
    "    river = list(map((lambda i: mj_list_utf8[i]), np.where(x.cpu().numpy())[1].tolist()))\n",
    "    if y is not None:\n",
    "        wait_y = list(map((lambda i: mj_list_utf8[i]), np.where(y.cpu().numpy())[0].tolist()))\n",
    "    wait_pred = pred.detach().cpu().numpy().tolist()\n",
    "    wait_pred = list(map((lambda l: f\"{mj_list_utf8[l[0]]}{l[1]:.4f}\"), enumerate(wait_pred)))\n",
    "    wait_pred.insert(27, \"<br>\")\n",
    "    wait_pred.insert(18, \"<br>\")\n",
    "    wait_pred.insert(9, \"<br>\")\n",
    "    output = f\"<div style='line-height:1em;font-size:30px'>\" + \\\n",
    "             f\"River (x)<br>{''.join(river[:6])}<br>{''.join(river[6:12])}<br>{''.join(river[12:])}<br>\" + \\\n",
    "             f\"\"\"{'' if y is None else f'Wait (y)<br>{\"\".join(wait_y)}<br><br>'}\"\"\" + \\\n",
    "             f\"Prediction<br>|{'|'.join(wait_pred)}|</div>\"\n",
    "    display(Markdown(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68b226fc-12e8-45d7-bb69-2ac6d9a7c65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style='line-height:1em;font-size:30px'>River (x)<br>🀙🀅🀡🀙🀔🀗<br>🀎🀔<br><br>Wait (y)<br>🀉<br><br>Prediction<br>|🀇0.9997|🀈1.0000|🀉1.0000|🀊1.0000|🀋0.9999|🀌1.0000|🀍0.9997|🀎0.0000|🀏0.8968|<br>|🀙0.0000|🀚0.9982|🀛0.9998|🀜0.9982|🀝1.0000|🀞0.9999|🀟0.9997|🀠0.9997|🀡0.0000|<br>|🀐0.9999|🀑0.2273|🀒0.9893|🀓0.9999|🀔0.0000|🀕0.6622|🀖0.0876|🀗0.0000|🀘0.4366|<br>|🀀0.0000|🀁0.0000|🀂0.0000|🀃0.0000|🀆0.0000|🀅0.0000|🀄︎0.0000|</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "x, y = next(iter(test_dl))\n",
    "x, y = x.to(\"cuda\"), y.to(\"cuda\")\n",
    "\n",
    "arr2mjutf8(x[0], model(x)[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29741c55-d163-44f6-be20-f28d529bb9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style='line-height:1em;font-size:30px'>River (x)<br>🀃🀚🀂🀐🀡🀊<br>🀗🀀🀌<br><br>Prediction<br>|🀇0.0001|🀈0.9375|🀉0.0001|🀊0.0000|🀋1.0000|🀌0.0000|🀍0.2411|🀎0.9999|🀏0.0060|<br>|🀙0.0001|🀚0.0000|🀛0.9998|🀜0.9999|🀝1.0000|🀞1.0000|🀟0.9999|🀠1.0000|🀡0.0000|<br>|🀐0.0001|🀑0.9998|🀒1.0000|🀓1.0000|🀔1.0000|🀕1.0000|🀖0.9999|🀗0.0000|🀘0.8126|<br>|🀀0.0000|🀁0.0000|🀂0.0000|🀃0.0000|🀆0.0000|🀅0.0000|🀄︎0.0000|</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "mj_list_utf8 = \"🀇🀈🀉🀊🀋🀌🀍🀎🀏🀙🀚🀛🀜🀝🀞🀟🀠🀡🀐🀑🀒🀓🀔🀕🀖🀗🀘🀀🀁🀂🀃🀆🀅🀄︎\"\n",
    "river_ = \"🀃🀚🀂🀐🀡🀊🀗🀀🀌\"\n",
    "river_ = list(map((lambda i: None if mj_list_utf8.index(i) == 34 else mj_list_utf8.index(i)), river_))\n",
    "river_ = list(filter((lambda i: i is not None), river_))\n",
    "river = np.zeros((24, 34), dtype=np.int8)\n",
    "river[np.arange(len(river_)), river_] = 1\n",
    "river = torch.tensor(np.expand_dims(river, 0).astype(np.float32)).to(\"cuda\")\n",
    "model.eval()\n",
    "arr2mjutf8(river[0], model(river)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ceaf2c5-6138-4422-9db1-c0fdb9924240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style='line-height:1em;font-size:30px'>River (x)<br>🀃🀚🀂🀐🀡🀗<br>🀀🀌<br><br>Prediction<br>|🀇0.9935|🀈1.0000|🀉0.9935|🀊1.0000|🀋1.0000|🀌0.0000|🀍0.9682|🀎0.9926|🀏0.0319|<br>|🀙0.0001|🀚0.0000|🀛0.9995|🀜0.9991|🀝1.0000|🀞1.0000|🀟0.9999|🀠0.9999|🀡0.0000|<br>|🀐0.0000|🀑0.9988|🀒1.0000|🀓1.0000|🀔0.9998|🀕1.0000|🀖1.0000|🀗0.0000|🀘0.1626|<br>|🀀0.0000|🀁0.0000|🀂0.0000|🀃0.0000|🀆0.0000|🀅0.0000|🀄︎0.0000|</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "mj_list_utf8 = \"🀇🀈🀉🀊🀋🀌🀍🀎🀏🀙🀚🀛🀜🀝🀞🀟🀠🀡🀐🀑🀒🀓🀔🀕🀖🀗🀘🀀🀁🀂🀃🀆🀅🀄︎\"\n",
    "river_ = \"🀃🀚🀂🀐🀡🀗🀀🀌\"\n",
    "river_ = list(map((lambda i: None if mj_list_utf8.index(i) == 34 else mj_list_utf8.index(i)), river_))\n",
    "river_ = list(filter((lambda i: i is not None), river_))\n",
    "river = np.zeros((24, 34), dtype=np.int8)\n",
    "river[np.arange(len(river_)), river_] = 1\n",
    "river = torch.tensor(np.expand_dims(river, 0).astype(np.float32)).to(\"cuda\")\n",
    "model.eval()\n",
    "arr2mjutf8(river[0], model(river)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051be64d-7e26-4ea7-bd98-a1438bc4389d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c60f436-5db3-484d-9d0a-30749630f934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0857be-2bef-4fcf-9ea3-48821dc0f512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
